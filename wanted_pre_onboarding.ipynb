{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wanted_pre_onboarding.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JG0ZRZF9Xorv",
        "FPIRh4hfXrkF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1) Tokenizer 생성하기"
      ],
      "metadata": {
        "id": "JG0ZRZF9Xorv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7eQuUSnmU3_P"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "class Tokenizer():\n",
        "   def __init__(self):\n",
        "     self.word_dict = {'oov': 0}\n",
        "     self.fit_checker = False\n",
        "  \n",
        "   def preprocessing(self, sequences):\n",
        "     result = []\n",
        "     # 문제 1-1\n",
        "     for sequence in sequences:\n",
        "       sequence = sequence.lower()\n",
        "       sequence = re.sub('[^a-z]', ' ', sequence)\n",
        "       sequence = sequence.split()\n",
        "       result.append(sequence)\n",
        "     return result\n",
        "  \n",
        "   def fit(self, sequences):\n",
        "     self.fit_checker = False\n",
        "     # 문제 1-2\n",
        "     tokens = self.preprocessing(sequences)\n",
        "     for token in tokens:\n",
        "       for word in token:\n",
        "         if word not in self.word_dict:\n",
        "           self.word_dict[word] = len(self.word_dict)\n",
        "     self.fit_checker = True\n",
        "  \n",
        "   def transform(self, sequences):\n",
        "     result = []\n",
        "     tokens = self.preprocessing(sequences)\n",
        "     if self.fit_checker:\n",
        "        # 문제 1-3\n",
        "       for token in tokens:\n",
        "         temp = []\n",
        "         for word in token:\n",
        "           if word in self.word_dict:\n",
        "             temp.append(self.word_dict[word])\n",
        "           else:\n",
        "             temp.append(self.word_dict['oov'])\n",
        "         result.append(temp)\n",
        "       return result\n",
        "     else:\n",
        "       raise Exception(\"Tokenizer instance is not fitted yet.\")\n",
        "      \n",
        "   def fit_transform(self, sequences):\n",
        "     self.fit(sequences)\n",
        "     result = self.transform(sequences)\n",
        "     return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2) TfidfVectorizer 생성하기"
      ],
      "metadata": {
        "id": "FPIRh4hfXrkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class TfidfVectorizer:\n",
        "   def __init__(self, tokenizer):\n",
        "     self.tokenizer = tokenizer\n",
        "     self.fit_checker = False\n",
        "  \n",
        "   def fit(self, sequences):\n",
        "     tokenized = self.tokenizer.fit_transform(sequences)\n",
        "     # 문제 2-1\n",
        "     self.idf_matrix = []\n",
        "     for i in range(len(self.tokenizer.vocab)):\n",
        "       self.idf_matrix.append(np.log(len(sequences)/(1+sum(tokenized[:,i]))))\n",
        "     self.fit_checker = True\n",
        "    \n",
        "\n",
        "   def transform(self, sequences):\n",
        "     if self.fit_checker:\n",
        "       tokenized = self.tokenizer.transform(sequences)\n",
        "       # 문제 2-2\n",
        "       self.tfidf_matrix = []\n",
        "       for i in range(len(sequences)):\n",
        "         self.tfidf_matrix.append([])\n",
        "         for j in range(len(self.tokenizer.vocab)):\n",
        "           self.tfidf_matrix[i].append(tokenized[i,j]*self.idf_matrix[j])\n",
        "       return self.tfidf_matrix\n",
        "     else:\n",
        "       raise Exception(\"TfidfVectorizer instance is not fitted yet.\")\n",
        "\n",
        "  \n",
        "   def fit_transform(self, sequences):\n",
        "     self.fit(sequences)\n",
        "     return self.transform(sequences)\n"
      ],
      "metadata": {
        "id": "mcMRK6H7U5MN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xKgqsPyqVSJE"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}